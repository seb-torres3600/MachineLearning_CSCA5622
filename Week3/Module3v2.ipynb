{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "QI5w3mueh_fC",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bf1d28544d99afa8e7fcf702ca0bbcf",
     "grade": false,
     "grade_id": "cell-ed2d3c3c54ab0e5a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Grading\n",
    "The final score that you will receive for your programming assignment is generated in relation to the total points set in your programming assignment itemâ€”not the total point value in the nbgrader notebook.<br>\n",
    "When calculating the final score shown to learners, the programming assignment takes the percentage of earned points vs. the total points provided by nbgrader and returns a score matching the equivalent percentage of the point value for the programming assignment. <br>\n",
    "**DO NOT CHANGE VARIABLE OR METHOD SIGNATURES** The autograder will not work properly if your change the variable or method signatures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc938b172db080b0b0dd8b93402b1f01",
     "grade": false,
     "grade_id": "cell-0a86eacd94d34225",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### WARNING\n",
    "Please refrain from using **print statements/anything that dumps large outputs(>500 lines) to STDOUT** to avoid running to into **memory issues**. \n",
    "Doing so requires your entire lab to be reset which may also result in loss of progress and you will be required to reach out to Coursera for assistance with this.\n",
    "This process usually takes time causing delays to your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "-CbEnw4Qh_fF",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee36857d89ae8fefbcfc467b3f0f8257",
     "grade": false,
     "grade_id": "cell-1c5f87edd003a29c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Validate Button\n",
    "Please note that this assignment uses nbgrader to facilitate grading. You will see a **validate button** at the top of your Jupyter notebook. If you hit this button, it will run tests cases for the lab that aren't hidden. It is good to use the validate button before submitting the lab. Do know that the labs in the course contain hidden test cases. The validate button will not let you know whether these test cases pass. After submitting your lab, you can see more information about these hidden test cases in the Grader Output. <br>\n",
    "***Cells with longer execution times will cause the validate button to time out and freeze. Please know that if you run into Validate time-outs, it will not affect the final submission grading.*** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "GzpgW7rVh_fH",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea87aef85c9f0bc770232e5bb0012cd2",
     "grade": false,
     "grade_id": "cell-838202c6a7fa608e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Module 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ine1vfOvh_fI",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c3e678f6fd66d3d58a4839d3398c7bd",
     "grade": false,
     "grade_id": "cell-cfff5f5c602da934",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# importing all the required libraries\n",
    "\n",
    "from math import exp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "h-pGpglsh_fK",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cea8628cb29283895fdad0fa2aa68b3d",
     "grade": false,
     "grade_id": "cell-fdc05c3ea8feddd7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Binary classification with logistic regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "NCknKqwyh_fM",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "011bd309a55a95e05cf36782d89d2318",
     "grade": false,
     "grade_id": "cell-46b248cc48bd7a15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part A [5 points]** : Your first task is to complete the function `gen_logistic` in the following cell so as to be able to generate the logistic function for a given input. The logistic function is a type of <em>sigmoid</em> function which has an 'S'-shape and 'squashes' its inputs to a value lying in the range [0,1]. Other sigmoid functions include the hyperbolic-tangent funcition (`tanh(x)`) and the error function (`erf(x)`). https://en.wikipedia.org/wiki/Sigmoid_function.\n",
    "Calculate sigmoid using the below formulas.\n",
    "\n",
    "<img src='sigmoid.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "deletable": false,
    "id": "aMCuZlq6h_fO",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88ee54af53d35221f5ea2d8a30d717fc",
     "grade": false,
     "grade_id": "cell-29a60883217c420b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gen_logistic(x, w=1, b=0):\n",
    "    \"\"\"\n",
    "    outputing the logistic output for an input x\n",
    "    :param x: scalar or numpy array of shape (n_samples, n_features). If only one feature, it must have the shape of (n_samples,1).\n",
    "    :param w: weight(s); either scalar or numpy array of shape (1, n_features)\n",
    "    :param b: bias; either scalar or numpy array of shape (1,)\n",
    "    returns y of shape (n_samples,)\n",
    "    \"\"\"    \n",
    "    # TODO: Finish this function to return the output of applying the sigmoid\n",
    "    # function to the input x (Please do not use external libraries) store \n",
    "    # the output in y and return y. Do not change the default parameter values.\n",
    "    # Hint: This function will be used in any input shape scalar (0d), 1d vector, and 2d arrays. Please make sure it can handle all those. Following reshaping codes might help.\n",
    "    # Hint2: You may use design matrix using concatenation, but it is not necesary.\n",
    "    \n",
    "    if np.isscalar(x):\n",
    "      x = np.array(x).reshape((1,1))\n",
    "    if np.isscalar(w):\n",
    "      w = np.array(w).reshape((1,1))\n",
    "    if np.isscalar(b):\n",
    "      b = np.array(b).reshape((1,1))  \n",
    "    if b.shape==(1,):\n",
    "      b= b.reshape((1,1))  \n",
    "\n",
    "    y_list = []\n",
    "    for i in range(len(x)):\n",
    "      z = np.dot(w, x[i]) + b\n",
    "      sig = 1 / (1 + np.exp(-1 * z))\n",
    "      y_list.append(sig)\n",
    "\n",
    "    y = np.array(y_list)\n",
    "    print(y.reshape(y.shape[0],))\n",
    "    return y.reshape(y.shape[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cc99588cbeae5b9c60f1c16c6467f5a",
     "grade": true,
     "grade_id": "cell-82b8afaa354d3097",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sample tests that gen_logistic function returns the output of applying the sigmoid function to the input x\n",
    "# ouput is stored and returned in y \n",
    "import pytest\n",
    "assert pytest.approx(gen_logistic(np.array([[2],[0.2],[17]])), 0.001) == np.array([0.88079708, 0.549834, 0.99999996]), \"Check the gen_logistic function.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "WM1MOPDph_fQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19ee8c43dadd99d2bcff4651dd1863dd",
     "grade": true,
     "grade_id": "cell-7d5fd878b994c224",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests that gen_logistic function returns the output of applying the sigmoid function to the input x\n",
    "# ouput is stored and returned in y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8AZTczpbh_fR",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36cd74f1988b06b6dc5453c027f9ddb9",
     "grade": false,
     "grade_id": "cell-e6ae2128caebffea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part B [5 points, Peer Review]:** Generate a vector x of length N with values lying between limits Xa and Xb (for this you will have to choose your own limits; play around with different values) and apply the `gen_logistic` function to this vector.  Proceed to plot the output and verify the shape of the output. If your decision boundary value is about the center of your x range, you will see an S-shape. Complete the Peer Review section for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "deletable": false,
    "id": "fLefLUBCh_fT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f2f70adc0fb30abb796827939ac9f17",
     "grade": false,
     "grade_id": "cell-6eb2c8a94fdaff49",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "b290dd20-c9e4-4287-c3ca-f9151a730317"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# TODO: change the values of N, a and b below to check how the output of your function works\n",
    "# Use a value for N greater than 1 and any limits a and b so that an S-shape graph is generated\n",
    "\n",
    "N = 1000\n",
    "Xa = -10\n",
    "Xb = 10\n",
    "w = 1\n",
    "b = 0\n",
    "\n",
    "x = np.expand_dims(np.linspace(Xa,Xb,N), axis=1)\n",
    "y = gen_logistic(x, w, b)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1,ncols=1,figsize=(12,7))\n",
    "ax.plot(x,y, lw=2)\n",
    "ax.set_xlabel(\"x\", fontsize=16)\n",
    "ax.set_ylabel(\"y\", fontsize=16)\n",
    "ax.set_title(\"Logistic/Sigmoid Function\", fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "xa68isiUh_fU",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a45d72918130acb144df290146616ccd",
     "grade": false,
     "grade_id": "cell-1851e5f2ab22640f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "***1. Increasing w will make the curve transition sharply: [2 pts, True/False]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "deletable": false,
    "id": "FnimQBqJh_fV",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "809a9da2ea06887cfdb768d8a8cf5d72",
     "grade": false,
     "grade_id": "cell-cba612162fd69391",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# uncomment sharp_transition and answer qustion 1. above \n",
    "# replace string with 'True' or 'False' \n",
    "# your code here\n",
    "\n",
    "sharp_transition = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "TtUJVzFDh_fX",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3767f5a3dc73e545b1ecb0f79e3aa4e4",
     "grade": true,
     "grade_id": "cell-633596ceba267a0f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell tests sharp_transition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ocQ0Bqe9h_fY",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c2ba7a0f060e684ffa41c132433513a",
     "grade": false,
     "grade_id": "cell-453dfedf075259ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "***2. If b increases by 1, then the decision boundary x decreases by 1: [3 pts, True/False]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "deletable": false,
    "id": "Q0OxXrIzh_fZ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "137a4d9089f0014c029b069a10f21a38",
     "grade": false,
     "grade_id": "cell-b6f28ec800691431",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# uncomment x_decreases_by_1 and answer question 2. above\n",
    "# replace string with 'True' or 'False' \n",
    "# your code here\n",
    "\n",
    "x_decreases_by_1 = 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "i7H9M3xLh_fa",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23d41626c13f2928852650663e740d43",
     "grade": true,
     "grade_id": "cell-b3d76497a5492f95",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell tests x_decreases_by_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yvMUPENoh_fb",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e635d94ca2662d18f820707f99f96c76",
     "grade": false,
     "grade_id": "cell-122d827f00590fd2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**PART C [10 pts, Peer Review]:** Performing binary classification using logistic regression on the breast-cancer dataset. In this part you will be exposed to different methods within the scikit-learn LogisticRegression class so you can build a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "-D3FCQkzh_fc",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c86bb6c193eea76dcbb547fb19ceea7b",
     "grade": false,
     "grade_id": "cell-2c47b2d74c67faa6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Import breast cancer dataset from sklearn** [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "deletable": false,
    "id": "e5rA60GFh_fe",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44470cbe104ebd8b203fff4e36a10789",
     "grade": false,
     "grade_id": "cell-10976d76d3a81f36",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Importing the breast-cancer dataset from sklearn datasets\n",
    "\n",
    "class BC_data:\n",
    "    \"\"\"\n",
    "    class to import the breast cancer dataset from sklearn\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        x, y = load_breast_cancer(return_X_y= True)\n",
    "        self.x_train = None \n",
    "        self.x_test = None \n",
    "        self.y_train = None \n",
    "        self.y_test = None\n",
    "        \n",
    "        # TODO: Split the data into training and test data (use train_test_split sklearn) \n",
    "        # such that the test data size is 25% of total number of observations\n",
    "        # No need to rescale the data. Use the data as is.\n",
    "        # Use random_state = 5\n",
    "        \n",
    "        # your code here\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(x, y, test_size=.25, random_state=5)\n",
    "        \n",
    "        \n",
    "        \n",
    "data = BC_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Ri8MXG63h_fe",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd7239d4f76f6b5117ae178700182413",
     "grade": true,
     "grade_id": "cell-b15826b530dfefea",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests that you properly split data into training and test data \n",
    "# such that test dat size is 25% of the total number of observations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "C9KZBu4lh_fg",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "decbc3170aabb4eaa78f6afba6b5adad",
     "grade": false,
     "grade_id": "cell-391383e2ba5d5778",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Build and Fit Logistic Regression Model [5 pts]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "_0Svx1tBh_fg",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b388f57db2bb6a5b1dddec6251a3b55",
     "grade": false,
     "grade_id": "cell-7c7287ce51bbec9b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "c65a2592-4cac-4f7e-b32e-5aadb541e52b"
   },
   "outputs": [],
   "source": [
    "# TODO: Use the data object and then train the logistic regression model. \n",
    "# 1. Change the code below to build the model called LogReg.\n",
    "# Use the Logistic Regression function from Sklearn library \n",
    "# and set up the logistic regression with the 'liblinear' solver.\n",
    "# 2. Fit the model to the train data\n",
    "\n",
    "LogReg = LogisticRegression(solver='liblinear').fit(data.x_train, data.y_train)\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "n3483zdNh_fh",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "747fad4dc1196db6de1984fa29b80695",
     "grade": false,
     "grade_id": "cell-6a47b85a473bed1a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "7759e1b5-120b-4c89-d3b4-2e9d169864c5"
   },
   "outputs": [],
   "source": [
    "# weights \n",
    "LogReg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "dHXE13gEh_fh",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84663600d6e73b9ef79ae61af0cb0943",
     "grade": true,
     "grade_id": "cell-813436dcc6ea1e10",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests LogReg model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "iGsaK5Ish_fi",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f36ad1ef1c75c82b99615d8936b97fe",
     "grade": false,
     "grade_id": "cell-2b87faad9230049f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the next cell, compute the ROC curve and the area under the curve and plot the ROC curve. Upload a copy or screenshot of the plot for this week's **Peer Review assignment**. \n",
    "\n",
    "Hint: sklearn.metrics has a function to calculate area under the curve.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "deletable": false,
    "id": "XnjZY4f_h_fj",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42b3c1f0d02548e7ae3abb749ce07fe0",
     "grade": false,
     "grade_id": "cell-5002bb7d0edf9fc7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "319a0a6d-c0c1-4bdc-fc73-380241946896"
   },
   "outputs": [],
   "source": [
    "# TODO: compute the area under the curve and plot ROC curve\n",
    "# Plot the ROC curve ( True positive rate v/s False positive rate) and indicate the AUC on the plot\n",
    "\n",
    "# your code here\n",
    "probability = LogReg.predict_proba(data.x_test)\n",
    "fpr, tpr, th = roc_curve(data.y_test, probability[: , 1])\n",
    "auc = roc_auc_score(data.y_test, probability[:, 1])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.plot([0, 1],[0,1], linestyle=\"--\", color=\"red\")\n",
    "plt.plot(fpr, tpr, color=\"blue\")\n",
    "plt.legend([\"AUC = 0.99\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "RMkUU_-wh_fj",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d4d0fe9f09585c192366b2fd3735ba79",
     "grade": false,
     "grade_id": "cell-af3b032af728ef45",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part D [5 pts, Peer Review]:** Here we will use the trained model coefficients and generate the `classification probabilities` using the `gen_logistic` function we built. The goal of this section is to make you understand how logistic regression classifies data points during and after training. Using the predictions from the generated probabilities, you will compute the precision and recall metrics (defined below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "deletable": false,
    "id": "zwhGiksfh_fj",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a60a0d8839dc5be028d090dacdce4b1",
     "grade": false,
     "grade_id": "cell-2332ba460f281cde",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_values(y_true, y_pred, pos_label_value=1.0):\n",
    "    TP = 0.0\n",
    "    TN = 0.0\n",
    "    FP = 0.0\n",
    "    FN = 0.0\n",
    "\n",
    "    # Validate they're the same length\n",
    "    assert len(y_true) ==  len(y_pred)\n",
    "\n",
    "    for i in range(len(y_true)):\n",
    "        truth = y_true[i]\n",
    "        pred = y_pred[i]\n",
    "        if truth == pred and pred == pos_label_value:\n",
    "            TP += 1\n",
    "        elif truth != pred and pred == pos_label_value:\n",
    "            FP += 1\n",
    "        elif truth == pred and pred !=  pos_label_value:\n",
    "            TN += 1\n",
    "        elif truth != pred and pred != pos_label_value:\n",
    "            FN += 1\n",
    "    \n",
    "    return TP, FP, TN, FN\n",
    "\n",
    "def calculate_precision(y_true, y_pred, pos_label_value=1.0):\n",
    "    '''\n",
    "    This function accepts the labels and the predictions, then\n",
    "    calculates precision for a binary classifier.\n",
    "    \n",
    "    Args\n",
    "        y_true: np.ndarray\n",
    "        y_pred: np.ndarray\n",
    "        \n",
    "        pos_label_value: (float) the number which represents the postiive\n",
    "        label in the y_true and y_pred arrays. Other numbers will be taken\n",
    "        to be the non-positive class for the binary classifier.\n",
    "    \n",
    "    Returns precision as a floating point number between 0.0 and 1.0\n",
    "    '''\n",
    "    TP, FP, TN, FN = get_values(y_true, y_pred, pos_label_value)\n",
    "    precision = TP / (TP + FP)\n",
    "    # your code here\n",
    "    return precision\n",
    "\n",
    "def calculate_recall(y_true, y_pred, pos_label_value=1.0):\n",
    "    '''\n",
    "    This function accepts the labels and the predictions, then\n",
    "    calculates recall for a binary classifier.\n",
    "    \n",
    "    Args\n",
    "        y_true: np.ndarray\n",
    "        y_pred: np.ndarray\n",
    "        \n",
    "        pos_label_value: (float) the number which represents the postiive\n",
    "        label in the y_true and y_pred arrays. Other numbers will be taken\n",
    "        to be the non-positive class for the binary classifier.\n",
    "    \n",
    "    Returns precision as a floating point number between 0.0 and 1.0\n",
    "    '''\n",
    "    \n",
    "    # your code here\n",
    "    TP, FP, TN, FN = get_values(y_true, y_pred, pos_label_value)\n",
    "    recall = TP / (TP + FN)\n",
    "\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6091dacb353dcbd06b0935da9c6a83b2",
     "grade": true,
     "grade_id": "cell-df419693fd8f73e8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sample Test cell \n",
    "ut_true = np.array([1.0, 1.0, 0.0, 1.0, 1.0, 0.0])\n",
    "ut_pred = np.array([1.0, 1.0, 1.0, 1.0, 0.0, 1.0])\n",
    "prec = calculate_precision(ut_true, ut_pred, 1.0)\n",
    "recall = calculate_recall(ut_true, ut_pred, 1.0)\n",
    "assert prec == 0.6, \"Check the precision value returned from your calculate_precision function.\"\n",
    "assert recall == 0.75, \"Check the recall value returned from your calculate_recall function.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "VlMA6tFmh_fl",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73820712243b7871bdfa56c324476ba5",
     "grade": true,
     "grade_id": "cell-f1e5ac4bdaa08fe0",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testing cell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "HEhFEFA4h_fl",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77bd03d6f1753a27b230235a8f3ffe40",
     "grade": false,
     "grade_id": "cell-118ff7dea1e21636",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the next cell you will generate the predictions for the test data `data.x_test` and compute prediction and recall metrics by calling the functions you built above. Take a screenshot of your code to submit for your **Peer Review assignment**. Make sure that you use the ***gen_logistic function***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "k9t7z2Byh_fm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "facfbba2d58056a75461cf1491dea251",
     "grade": false,
     "grade_id": "cell-176f3759a371e25b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "b4b9fa82-3388-4eb7-cb57-edd6c3bc04ed"
   },
   "outputs": [],
   "source": [
    "# TO-DO : Generate predicted y values using coefficients of the fit logistic regression model for data.x_test\n",
    "# Then compute and print the precision and recall metrics \n",
    "predictions = gen_logistic(data.x_test, LogReg.coef_, LogReg.intercept_)\n",
    "\n",
    "y_pred = [0] * len(predictions)\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] >= 0.5:\n",
    "        y_pred[i] = 1\n",
    "# your code here\n",
    "\n",
    "precision = calculate_precision(data.y_test, y_pred)\n",
    "recall = calculate_recall(data.y_test, y_pred)\n",
    "\n",
    "\n",
    "print('Model Precision : %0.2f' % precision)\n",
    "print('Model Recall : %0.2f' % recall)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Module3_update.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
